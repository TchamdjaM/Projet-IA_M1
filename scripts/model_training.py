# ğŸ“¦ Imports
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import mean_squared_error
import joblib
import os

# ğŸ“¥ Chargement des donnÃ©es nettoyÃ©es
df = pd.read_csv("data/processed/cleaned_data.csv")
df["Date"] = pd.to_datetime(df["Date"])

# ğŸ§  Feature engineering
df["dayofweek"] = df["Date"].dt.dayofweek  # Jour de la semaine

# ğŸ¯ Variables explicatives et cible
X = df[["Product line", "City", "Unit price", "dayofweek"]]
y = df["Quantity"]

# ğŸ”¤ Encodage des colonnes catÃ©gorielles (âœ… paramÃ¨tre corrigÃ©)
encoder = OneHotEncoder(sparse_output=False)
X_encoded = encoder.fit_transform(X[["Product line", "City"]])
X_numeric = X[["Unit price", "dayofweek"]].values

# ğŸ”— Fusion des colonnes encodÃ©es et numÃ©riques
X_final = np.concatenate([X_encoded, X_numeric], axis=1)

# ğŸ”€ SÃ©paration en train/test
X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)

# ğŸŒ² EntraÃ®nement du modÃ¨le
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# ğŸ” Ã‰valuation
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f"Erreur quadratique moyenne (MSE) : {mse:.2f}")

# ğŸ’¾ Sauvegarde du modÃ¨le et de lâ€™encodeur
os.makedirs("models", exist_ok=True)
joblib.dump(model, "models/demand_model.pkl")
joblib.dump(encoder, "models/encoder.pkl")

# ğŸ“¤ GÃ©nÃ©ration du CSV de prÃ©dictions
X_raw = X.iloc[X_test.argmax(axis=1)]
X_raw["Predicted Quantity"] = y_pred

# Export
os.makedirs("Output", exist_ok=True)
X_raw.to_csv("../PROJET IA_M1/Output/prediction.csv", index=False)
print("[âœ…] Fichier prediction.csv exportÃ©.")
